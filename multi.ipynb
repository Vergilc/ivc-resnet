{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yilun\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import torchnet.meter.confusionmeter as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black widow',\n",
       " 'captain america',\n",
       " 'doctor strange',\n",
       " 'hulk',\n",
       " 'ironman',\n",
       " 'loki',\n",
       " 'spider-man',\n",
       " 'thanos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation & test\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandAugment(),   # random augmentation\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'marvel'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#lists for graph generation\n",
    "epoch_counter_train = []\n",
    "epoch_counter_val = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch +1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                #scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            #For graph generation\n",
    "            if phase == \"train\":\n",
    "                train_loss.append(running_loss/dataset_sizes[phase])\n",
    "                train_acc.append(running_corrects.double().cpu() / dataset_sizes[phase])\n",
    "                epoch_counter_train.append(epoch)\n",
    "            if phase == \"valid\":\n",
    "                val_loss.append(running_loss/ dataset_sizes[phase])\n",
    "                val_acc.append(running_corrects.double().cpu() / dataset_sizes[phase])\n",
    "                epoch_counter_val.append(epoch)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            #for printing        \n",
    "            if phase == \"train\":    \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == \"valid\":    \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the best model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # final validation for each class\n",
    "    for phase in ['valid']:\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        y_true = []\n",
    "        y_pre = []\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                y_true.extend(labels.to('cpu'))\n",
    "                y_pre.extend(preds.to('cpu'))\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        print(classification_report(y_true,y_pre))\n",
    "\n",
    "        #for printing        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        \n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "    print()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "Epoch 1/50\n",
      "----------\n",
      "train Loss: 1.9964 Acc: 0.2175\n",
      "valid Loss: 2.0181 Acc: 0.2217\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "train Loss: 1.9217 Acc: 0.2492\n",
      "valid Loss: 1.9809 Acc: 0.2328\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "train Loss: 1.9168 Acc: 0.2485\n",
      "valid Loss: 1.8350 Acc: 0.2616\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "train Loss: 1.8915 Acc: 0.2721\n",
      "valid Loss: 1.9627 Acc: 0.2506\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "train Loss: 1.8734 Acc: 0.2670\n",
      "valid Loss: 1.7685 Acc: 0.3304\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "train Loss: 1.8558 Acc: 0.2883\n",
      "valid Loss: 1.7826 Acc: 0.3570\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "train Loss: 1.8480 Acc: 0.2953\n",
      "valid Loss: 1.7962 Acc: 0.3392\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "train Loss: 1.8355 Acc: 0.3104\n",
      "valid Loss: 1.6550 Acc: 0.3836\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "train Loss: 1.8050 Acc: 0.3200\n",
      "valid Loss: 1.7871 Acc: 0.3392\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "train Loss: 1.7755 Acc: 0.3471\n",
      "valid Loss: 1.7543 Acc: 0.3415\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "train Loss: 1.6984 Acc: 0.3622\n",
      "valid Loss: 1.5768 Acc: 0.4302\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "train Loss: 1.6741 Acc: 0.3769\n",
      "valid Loss: 1.5360 Acc: 0.4457\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "train Loss: 1.6451 Acc: 0.4044\n",
      "valid Loss: 1.5162 Acc: 0.4279\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "train Loss: 1.6194 Acc: 0.4125\n",
      "valid Loss: 1.5096 Acc: 0.4257\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "train Loss: 1.5945 Acc: 0.4211\n",
      "valid Loss: 1.4985 Acc: 0.4545\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "train Loss: 1.5601 Acc: 0.4350\n",
      "valid Loss: 1.4610 Acc: 0.4590\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "train Loss: 1.5431 Acc: 0.4431\n",
      "valid Loss: 1.4602 Acc: 0.4878\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "train Loss: 1.5488 Acc: 0.4509\n",
      "valid Loss: 1.4560 Acc: 0.4701\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "train Loss: 1.5163 Acc: 0.4741\n",
      "valid Loss: 1.4020 Acc: 0.4900\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "train Loss: 1.4923 Acc: 0.4687\n",
      "valid Loss: 1.4201 Acc: 0.4745\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "train Loss: 1.4738 Acc: 0.4737\n",
      "valid Loss: 1.3734 Acc: 0.5011\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "train Loss: 1.4676 Acc: 0.4872\n",
      "valid Loss: 1.3797 Acc: 0.4945\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "train Loss: 1.4447 Acc: 0.4934\n",
      "valid Loss: 1.3677 Acc: 0.4900\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "train Loss: 1.4468 Acc: 0.4919\n",
      "valid Loss: 1.3602 Acc: 0.4989\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "train Loss: 1.4667 Acc: 0.4865\n",
      "valid Loss: 1.3548 Acc: 0.5033\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "train Loss: 1.4447 Acc: 0.4992\n",
      "valid Loss: 1.3493 Acc: 0.5033\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "train Loss: 1.4410 Acc: 0.4946\n",
      "valid Loss: 1.3529 Acc: 0.5033\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "train Loss: 1.4683 Acc: 0.4822\n",
      "valid Loss: 1.3503 Acc: 0.4900\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "train Loss: 1.4456 Acc: 0.4872\n",
      "valid Loss: 1.3380 Acc: 0.5166\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "train Loss: 1.4460 Acc: 0.5058\n",
      "valid Loss: 1.3527 Acc: 0.4989\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "train Loss: 1.4236 Acc: 0.5077\n",
      "valid Loss: 1.3387 Acc: 0.5011\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "train Loss: 1.4242 Acc: 0.5058\n",
      "valid Loss: 1.3421 Acc: 0.5100\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "train Loss: 1.4472 Acc: 0.4923\n",
      "valid Loss: 1.3472 Acc: 0.5055\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "train Loss: 1.4334 Acc: 0.4973\n",
      "valid Loss: 1.3501 Acc: 0.5122\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "train Loss: 1.4294 Acc: 0.4954\n",
      "valid Loss: 1.3370 Acc: 0.4922\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "train Loss: 1.4236 Acc: 0.5050\n",
      "valid Loss: 1.3378 Acc: 0.5055\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "train Loss: 1.4203 Acc: 0.5015\n",
      "valid Loss: 1.3502 Acc: 0.4900\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "train Loss: 1.4351 Acc: 0.4872\n",
      "valid Loss: 1.3412 Acc: 0.5011\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "train Loss: 1.4200 Acc: 0.5066\n",
      "valid Loss: 1.3407 Acc: 0.5078\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "train Loss: 1.4103 Acc: 0.5089\n",
      "valid Loss: 1.3450 Acc: 0.5011\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "train Loss: 1.4429 Acc: 0.4965\n",
      "valid Loss: 1.3488 Acc: 0.4812\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "train Loss: 1.4258 Acc: 0.5031\n",
      "valid Loss: 1.3423 Acc: 0.4945\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "train Loss: 1.4225 Acc: 0.5077\n",
      "valid Loss: 1.3355 Acc: 0.4989\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "train Loss: 1.3985 Acc: 0.5085\n",
      "valid Loss: 1.3430 Acc: 0.4922\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "train Loss: 1.4259 Acc: 0.5108\n",
      "valid Loss: 1.3394 Acc: 0.4945\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "train Loss: 1.4344 Acc: 0.4888\n",
      "valid Loss: 1.3448 Acc: 0.5144\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "train Loss: 1.4140 Acc: 0.5039\n",
      "valid Loss: 1.3401 Acc: 0.5144\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "train Loss: 1.4567 Acc: 0.4965\n",
      "valid Loss: 1.3389 Acc: 0.4967\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "train Loss: 1.4221 Acc: 0.4942\n",
      "valid Loss: 1.3423 Acc: 0.5211\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "train Loss: 1.4241 Acc: 0.5031\n",
      "valid Loss: 1.3377 Acc: 0.4856\n",
      "\n",
      "Training complete in 12m 16s\n",
      "Best val Acc: 0.521064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.33      0.35        55\n",
      "           1       0.40      0.37      0.39        57\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.63      0.61      0.62        56\n",
      "           4       0.39      0.57      0.46        56\n",
      "           5       0.40      0.30      0.34        54\n",
      "           6       0.75      0.77      0.76        57\n",
      "           7       0.49      0.65      0.56        55\n",
      "\n",
      "    accuracy                           0.49       451\n",
      "   macro avg       0.48      0.49      0.48       451\n",
      "weighted avg       0.48      0.49      0.48       451\n",
      "\n",
      "valid Loss: 1.3377 Acc: 0.4856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Using a model pre-trained on ImageNet and replacing it's final linear layer\n",
    "\n",
    "#For resnet18 or resnet50\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print(num_ftrs)\n",
    "model_ft.fc = nn.Sequential(\n",
    "    #nn.Flatten(),\n",
    "    nn.Linear(num_ftrs, 128),\n",
    "    #nn.Sigmoid(),\n",
    "    nn.ReLU(),\n",
    "    #nn.Softmax(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(128,32),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(32, 8),\n",
    "    )\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Using Adam as the parameter optimizer\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)       \n",
    "\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the train & validation losses\n",
    "plt.figure(1)\n",
    "plt.title(\"Training Vs Validation Losses\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_counter_train,train_loss,color = 'r', label=\"Training Loss\")\n",
    "plt.plot(epoch_counter_val,val_loss,color = 'g', label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('loss_2.jpg')\n",
    "plt.show()\n",
    "\n",
    "#Plot the accuracies in train & validation\n",
    "plt.figure(2)\n",
    "plt.title(\"Training Vs Validation Accuracies\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_counter_train,train_acc,color = 'r', label=\"Training Accuracy\")\n",
    "plt.plot(epoch_counter_val,val_acc,color = 'g', label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig('acc_2.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test the accuracy with test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_ft(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "#Class wise testing accuracy\n",
    "class_correct = list(0. for i in range(8))\n",
    "class_total = list(0. for i in range(8))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_ft(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            point = (predicted == labels).squeeze()\n",
    "            for j in range(len(labels)):\n",
    "                label = labels[j]\n",
    "                class_correct[label] += point[j].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "for i in range(8):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        class_names[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "\n",
    "#Get the confusion matrix for testing data\n",
    "confusion_matrix = cm.ConfusionMeter(8)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        confusion_matrix.add(predicted, labels)\n",
    "    print(confusion_matrix.conf)\n",
    "\n",
    "#Confusion matrix as a heatmap\n",
    "con_m = confusion_matrix.conf\n",
    "df_con_m = pd.DataFrame(con_m, index= [i for i in class_names], columns = [i for i in class_names])\n",
    "sn.set(font_scale= 1.1)\n",
    "sn.heatmap(df_con_m, annot=True,fmt='g' ,  annot_kws={\"size\" : 10}, cbar = False, cmap=\"Blues\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad92f5eebf0019fa9ddc6ae79c8e7fb84c6e24d3e5471f88ddc999184786ec9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
